events_saved <- readRDS("~/Desktop/Reporting in digital age/my_quatro_site/events_saved.rds")
View(events_saved)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(DT)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(DT)
#### PRESIDENTIAL CANDIDATE TRIPS ####
# Load in data of prez candidate campaign trips between midterms and end of Jan
events <- readRDS("events_saved.rds")
#We can use the "DT" package to easily make a sortable, filterable, searchable data table
#Just this little bit of code does a whole lot - check it out:
DT::datatable(events)
#We can already sort, but what if we want to allow the table to be FILTERED too?
#It's easy, we just add:
DT::datatable(events,
rownames = FALSE,
filter = "top"# <--- NEW STUFF HERE
)
#Now hmm, what's up with the filters on the text columns? Why aren't they working?
#It's because of a quirk in DT tables where filters will only work on text that is converted to a factor
#So let's do that
events <- events %>%
mutate(
state = as_factor(state),
event_type = as.factor(event_type)
)
#Now let's try the DT table code again and see if it worked
DT::datatable(events,
rownames = FALSE,
filter = "top")
#Now, for the coup de gr?ce
#let's add some buttons at the top of the page to let people copy, download, etc
#we do that using a DT "extenstion" called, you guessed it, Buttons
# https://rstudio.github.io/DT/extensions.html
DT::datatable(events,
rownames = FALSE,
filter = "top",
extensions = 'Buttons',
options = list(   # <--- NEW STUFF STARTS HERE
dom = 'Bfrtip',
buttons = c('copy', 'csv', "excel")
)) %>%
DT::formatStyle('cand_lastname',  color = 'red', fontWeight = 'bold')
## saving the result
# first we just need to assign our table to a variable...
mytable <- DT::datatable(events,
rownames = FALSE,
filter = "top",
extensions = 'Buttons',
options = list(
dom = 'Bfrtip',
buttons = c('copy', 'csv', "excel")
)) %>%
DT::formatStyle('cand_lastname',  color = 'red', fontWeight = 'bold')
# ... then just run this simple bit of code to export to html
DT::saveWidget(mytable, "mytable.html")
# We've now created a working web page that can be put anywhere on the internet we choose
# Yay!
# If we stay within the world of quarto though we don't need to export it, we can just display it
# within the quarto page of course
events %>%
head(5) %>%
DT::datatable(rownames = FALSE,
options = list(searching = FALSE, paging = FALSE, dom = "tip"))
events %>%
select(date, cand_lastname, city) %>%
head(5) %>%
DT::datatable(rownames = FALSE,
options = list(searching = FALSE, paging = FALSE, dom = "tip"))
events %>%
select(-description) %>%
head(5) %>%
DT::datatable(rownames = FALSE,
options = list(searching = FALSE, paging = FALSE, dom = "tip"))
knitr::opts_chunk$set(echo = TRUE)
#Load libraries
library(tidyverse)
library(janitor)
library(readxl)
library(scales)
library(lubridate)
library(tidyverse)
library(tigris)
library(sf)
library(tmap)
library(tmaptools)
library(htmltools)
library(janitor)
library(rmapshaper)
library(here)
options(tigris_class = "sf")
ggplot(ten_drop_sen, aes(x = reorder(county, pct_r_above_trump) , y = pct_r_above_trump)) +
geom_col()
events_saved <- readRDS("~/Desktop/Reporting in digital age/my_quatro_site/events_saved.rds")
View(events_saved)
library(tidyverse)
library(janitor)
library(httr)
library(jsonlite)
library(kableExtra)
library(here)
options(scipen = 999)
options(stringsAsFactors = FALSE)
joined_vacomparison <- readRDS(here("processed_data", "joined_vacomparison.rds"))
#Using the DT package, I am creating an table pulling from the "joined_vacomparison" data set we loaded
DT::datatable(joined_vacomparison,
#Since we want a paginated datatable, we are going to make sure to have                        "rownames" equal "TRUE"
rownames = TRUE,
#To make the table more interactive we are going to add a "filer" option at the                "top" of the table to search through data as needed
filter = "top",
#Additionally, we are going to add the option of downloading the data set with                 the "copy", "CSV", and "Excel" buttons using the next 4 lines of code
extensions = 'Buttons',
options = list(
dom = 'Bfrtip',
buttons = c('copy', 'csv', "excel")
)) %>%
#To make the locality names clearer, the defining data point of each record, we are going to   use "formatStyle" to bold the locality name text and color it red
DT::formatStyle('locality',  color = 'red', fontWeight = 'bold')
#First, to make this chart we have to create a new column. To do this we are going to use the mutate function. We are using the "pct_youngkin" and the "trump_pct" columns which both hold the pecentage of the vote each candidate recieved in their race. Subtracting the two will give us the difference which will be displayed in this new "Y_vs_T" column in the new Y_T_chart data set which will be used in the following code for the ggplot chart.
Y_T_chart <- joined_vacomparison %>%
mutate(
Y_vs_T = pct_youngkin - trump_pct
)
#In order to get the Top 5 localities like we want, we have to arrange the data from biggest to smallest using the arrange function. We use "desc" as well since the default is smallest to largest.
ordered_Y_T_chart <- Y_T_chart %>% arrange(desc(Y_vs_T))
#Now that the data is ordered correctly we can use the head function to get just the first 5 which will be the largest.
short_Y_T_chart<- head(ordered_Y_T_chart, 5)
#using GGPlot we can now use this shortened, ordered data as the data set to pull from. Using locality name as the independent variable and our new Youngkin vs Trump column as our dependent variable, this table visualizes the top 5 localties with the largest percentage difference.
#we use "reorder" for the locality so that the bars appear in descending percentage order as well.
#Using "fill" I also assigned the chart a red hex code to have a better visual appeal
#I also assigned a fitting y axis and x axis name as well as a title to make the chart easier to read
#I used "coord_flip()" as the localities names were too mushed together in the default display
ggplot(short_Y_T_chart, aes(x = reorder(locality, Y_vs_T), y = Y_vs_T)) +
geom_col(fill = "#B33F40") +
scale_y_continuous(name = "Youngkin percentage points vs Trump") +
scale_x_discrete(name = "Locality Name") +
ggtitle("Youngkin vs Trump Percentage Difference by Locality (Top 5)") +
coord_flip()
View(short_Y_T_chart)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(nycflights13) # <- make sure to install this package
library(tigris)
library(tidycensus)
library(tmap)
library(tmaptools)
library(janitor)
library(writexl)
library(here)
options(tigris_class = "sf")
#naming this function "summun" we want the function to run on two arguments, "x" and "y" which will be the two numbers we want to add together
sumnum <- function(x, y) {
#the function will perform the simple arithmetic function as coded here
result <- x+y
#we want to make sure the result is actually displayed in the end so we      will make sure to include a return line
return(result)
}
#Here is the function in action
sumnum(2,3)
mean_function <- function(mean_vector){
result <- mean(mean_vector)
return(result)
}
mean_function(1,2,3)
mean_function(c(1,2,3))
#Now we are adding a print factor
mean_function_print <- function(mean_vector){
#Here we want the result object to include this "paste0" function in addition to the "mean" function. We can have the text always start off with "The mean is " making sure to add a space at the end and have the sentence end with what ever mean value to function calculates.
result <- paste0("The mean is ", mean(mean_vector))
#again make sure to include the return line to display a result
return(result)
}
#here is the funciton in action
mean_function_print(c(1,2,3))
#load the data to use for the rest of the assignment questions
flights <- nycflights13::flights
head(flights)
View(flights)
View(joined_vacomparison)
#This function's argument will be the abbreviation of the airport name
filter_airport <- function(airport){
#using the filter function with the airport abbreviation will return information for only the airport selected
result <- filter(flights, origin == airport)
#make sure to include the return line to display a result
return(result)
}
#example of function
filter_airport("EWR")
#This function will build off our previous function, again the argument remains the same, the airport abbreviation
new_filter_airport <- function(airport){
#filter function information remains the same
flight_data_set <- filter(flights, origin == airport)
#the result will change slights to
result <- flight_data_set %>%
group_by(carrier) %>%
summarise(count=n())
return(result)
}
new_filter_airport("LGA")
View(mean_function_print)
myvars <- c(education_total = "B06009_001",
education_bachelors = "B06009_005",
education_gradprofess = "B06009_006")
#To do this we will use the "get_acs" function that is a part of the tidycensus package. Since we want the state level, we will make sure geography = "state" and we will make sure geometry = TRUE to pull down the geospatial/mapping data tied to each state
get_acs(geography = "state",
variables = myvars,
output = "wide",
geometry = TRUE)
#to do this we will name and save the data set created with the "get_acs" function
allstates_wide <- get_acs(geography = "state",
variables = myvars,
output = "wide",
geometry = TRUE)
#now lets create a new data set called "clean_allstates_wide" that is cleaned up using the "select" function removing, using the "-" character, all columns that end with "m" as that denotes the margin of error columns
clean_allstates_wide <- allstates_wide %>%
select(-ends_with("M"))
#here is the new clean data set
clean_allstates_wide
#Since the Census counts people with a bachelor's only vs. a graduate degree separately, we will need to combine the two categories before making our calculation against the total population column. To do this we will use the mutate function to combine "education_bachelorsE" and "education_gradprofessE"
new_clean_allstates_wide <- clean_allstates_wide %>%
mutate(bach_or_higher = education_bachelorsE + education_gradprofessE)
#With that new combined column created we can use the mutate function again to create the percentage column
pctdata_new_clean_allstates_wide <- new_clean_allstates_wide %>%
mutate(pct_ed_bach_or_higher = (bach_or_higher / education_totalE) *100)
#here is the data set with out new columns
pctdata_new_clean_allstates_wide
#First we need to use the filter function to filter out Alaska, Hawaii and Puerto Rico
NEW_pctdata_new_clean_allstates_wide <- pctdata_new_clean_allstates_wide %>%
#using "!=" will filter out the values listed
filter(NAME != "Alaska", NAME !="Hawaii", NAME !="Puerto Rico")
#here is the filtered data
NEW_pctdata_new_clean_allstates_wide
#Now we will use the tmap package to create a shaded map that shows the percentage of Bachelor's-and-higher populations in each state.
tmap_mode(mode = "plot")
#make sure to use the new filtered data set for the map
tm_shape(NEW_pctdata_new_clean_allstates_wide) +
#use "pct_ed_bach_or_higher" so the package knows which value to shade by and "GEOID"
tm_polygons("pct_ed_bach_or_higher", id = "GEOID")
View(NEW_pctdata_new_clean_allstates_wide)
View(pctdata_new_clean_allstates_wide)
View(short_Y_T_chart)
